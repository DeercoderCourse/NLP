  ####  Input: token file (one review per line; tokens are delimited by white space) 
  ####         label file (one label per line)
  ####  These input files were generated by prep_elec.sh and included in the package. 

  gpu=-1  # <= change this to, e.g., "gpu=0" to use a specific GPU. 
  mem=4   # pre-allocate 4GB device memory 
  gpumem=${gpu}:${mem}
  dir=../elec # <= change this to where the Elec dataset is.  

  options="LowerCase UTF8"

  for sz in 05k 10k 50k 100k 200k; do
    #---  Step 1. Generate vocabulary
    echo Generaing vocabulary from training data ... $sz ... 

    max_num=30000
    vocab_fn=data/elec-${sz}_trn-${max_num}.vocab
  
    ../bin/prepText gen_vocab input_fn=${dir}/elec-${sz}-train.txt.tok vocab_fn=$vocab_fn max_vocab_size=$max_num \
                              $options WriteCount 


    #---  Step 2. Generate region files (data/*.xsmatvar) and target files (data/*.y) for training and testing CNN.  
    #     We generate region vectors of the convolution layer and write them to a file, instead of making them 
    #     on the fly during training/testing.  
    echo 
    echo Generating region files ... $sz ... 
    for set in train test; do 
      for pch_sz in 3 4; do
        rnm=data/elec-${sz}_${set}-p${pch_sz}
        inp_fn=${dir}/elec-${sz}-${set}
        if [ "$set" = "test" ]; then
          inp_fn=data/elec-${set}
        fi

        #---  NOTE: The parameters are the same as IMDB.  
        ../bin/prepText $prep_exe gen_regions \
          region_fn_stem=$rnm input_fn=$inp_fn vocab_fn=$vocab_fn \
          $options text_fn_ext=.txt.tok label_fn_ext=.cat \
          label_dic_fn=data/elec_cat.dic \
          patch_size=${pch_sz} patch_stride=1 padding=$((pch_sz-1))
      done
    done


    #---  Step 3. Training and test using GPU
    log_fn=log_output/elec-${sz}-seq2.log
    perf_fn=perf/elec-${sz}-seq2-perf.csv
    echo 
    echo Training CNN and testing ... $sz ...
    echo This takes a while.  See $log_fn and $perf_fn for progress and see param/seq2.param for the rest of the parameters. 
    nodes=1000
    if [ "$sz" = "05k" ] || [ "$sz" = "10k" ]; then
      stepsize=0.5
    else
      stepsize=0.25
    fi
    ../bin/conText $gpumem cnn \
           nodes=$nodes resnorm_width=$nodes \
           data_dir=data trnname=elec-${sz}_train- tstname=elec-${sz}_test- \
           data_ext0=p3 data_ext1=p4 \
           reg_L2=0 top_reg_L2=1e-3 step_size=$stepsize top_dropout=0.5 \
           LessVerbose test_interval=25 evaluation_fn=$perf_fn \
           @param/seq2.param > ${log_fn}
  done
