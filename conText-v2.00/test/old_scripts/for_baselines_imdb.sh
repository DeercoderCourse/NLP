  ####  Input: token file (one review per line; tokens are delimited by white space) 
  ####         label file (one label per line)
  ####  These input files were generated by prep_imdb.sh and included in the package. 
  ####  To find the order of the data points, see prep_imdb.sh and the files at lst/. 
  ####  
  ####  To display help on Step 1: enter "../bin/prepText gen_vocab"
  ####                     Step 2:       "../bin/prepText gen_b_feat"

  #---  Step 1. Generate vocabulary
  echo Generaing uni-, bi-, and tri-gram vocabulary files from training data ... 

  options="LowerCase UTF8"

  for nn in 1 2 3; do
    vocab_fn=data/imdb_trn-${nn}gram.vocab  
    ../bin/prepText gen_vocab input_fn=data/imdb-train.txt.tok vocab_fn=$vocab_fn \
                              $options WriteCount n=$nn
  done 

  #---  Step 2. Generate bag-of-ngram files ...
  echo 
  echo Generating bag-of-ngram files ... 
  for nn in 1 2 3; do
    if [ "$nn" = "1" ]; then
      voc_fn=data/imdb_trn-1gram.vocab
    elif [ "$nn" = "2" ]; then
      voc_fn=data/imdb_trn-12gram.vocab
      cat data/imdb_trn-1gram.vocab  >$voc_fn
      cat data/imdb_trn-2gram.vocab >>$voc_fn
    elif [ "$nn" = "3" ]; then
      voc_fn=data/imdb_trn-123gram.vocab
      cat data/imdb_trn-1gram.vocab  >$voc_fn
      cat data/imdb_trn-2gram.vocab >>$voc_fn
      cat data/imdb_trn-3gram.vocab >>$voc_fn
    else
      echo "what?!"
      exit
    fi
    for set in train test; do
      outnm=data/imdb_${set}-bow${nn}
      ../bin/prepText gen_b_feat \
         vocab_fn=$voc_fn \
         input_fn=data/imdb-${set} \
         output_fn_stem=$outnm \
         $options text_fn_ext=.txt.tok label_fn_ext=.cat \
         label_dic_fn=data/imdb_cat.dic \
         Binary Unit

      #---  To convert the bag-of-ngram feature file and the target file to the svmLight format ... 
      # echo Converting to the svmLight format ... 
      # perl conv.pl $outnm 0 > ${outnm}.cat0.xy
    done
  done

  #---  Retain the most frequent n-grams in the vocabulary only
#  echo 
#  echo Merging and sorting n-grams ... 
#  maxk=30
#  voc_fn=data/imdb_trn-123gram-${maxk}k.vocab
#  perl merge_dic.pl ${maxk}000 data/imdb_trn-1gram.vocab data/imdb_trn-2gram.vocab data/imdb_trn-3gram.vocab >$voc_fn
