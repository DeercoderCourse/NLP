\documentclass{article}
\usepackage{datenumber}
\usepackage{indentfirst}

\title{Weekly Update for NLP Project \#3}
\author{Chang Liu}

\setdatetoday
\addtocounter{datenumber}{-3}
\setdatebynumber{\thedatenumber}

\date{\datedate}

\begin{document}

\maketitle

\section{Introduction}


This document is used to record the weekly update for me in my NLP project. This is the 3rd update for our project in 3nd week.

\section{Identify your project topic}

I plan to do something related with my focus on \textbf{CNN}(Convolutional Neural Network), so I still try to find some work that can combine CNN with the text processing tasks.

\section{Explore related literature} 
I have finished the paper reading and the remaining problems in that referred paper. After examining their project website, I get more ideas about their system architecture and system implementation. For the rest the week, I spend some time reading their guide on their system installing and example program, which gives me much ideas about what they have done in the paper


\section{Identify relevant data sets}

During this week, I also download their data and run their experiment, even though it takes me some time to deploy the system, I still can make it work and get some primary result. Some of their implementation is missing, but from their future work, I get some plan for the next step, especially about how to improve the precision of the classification.



\section{Set up and execute the annotation task (if applicable)} 
It takes some time to deploy the system under Ubuntu, as it takes some time to fix the dependence in Ubuntu, and the build from the source code of the project is also a challenge at first.



\section{Adapt external libraries}
\textbf{NA}


\section{Implement your system}
\textbf{NA}


\section{Evaluate your system performance}
\textbf{NA}

\section{Summary}

In this week, I fix some remaining issues from last week and start to read their code and system architecture. That makes me more clear about what they write in the papers. And I also start trying to deploy the system and run some experiments, which gives me a rough idea about their result. After getting familiar with their framework and data, I find that the main problem left for this task is that I still don't get deep into their code, so how they use vectors of words and combine the CNN structure is still unclear to me. 

The plan for next week is to read their code implementation and try to fix that main problem. If I have more time, I will try to modify it and see the influence of change on their algorithms to verify my hypnosis.

\end{document}